name: 'Code Reviewer'
description: 'Comprehensive code review system with security, performance, testing, and quality analysis'
author: 'Agent OS Team'

inputs:
  review-type:
    description: 'Type of review to run (audit, security, review)'
    required: false
    default: 'audit'
  project-path:
    description: 'Path to the project to review'
    required: false
    default: '.'
  project-type:
    description: 'Project type (backend-api, dashboard-ui, data-pipeline, infrastructure, or auto)'
    required: false
    default: 'auto'
  fail-on-blockers:
    description: 'Fail the workflow if merge blockers are found'
    required: false
    default: 'true'
  fail-on:
    description: 'Granular fail conditions (e.g., "security:high,security:critical,test:critical")'
    required: false
    default: ''
  comment-on-pr:
    description: 'Comment on PR with review results'
    required: false
    default: 'true'
  upload-reports:
    description: 'Upload review reports as artifacts'
    required: false
    default: 'true'
  # AI Provider Configuration
  ai-provider:
    description: 'AI provider to use: anthropic, openai, ollama, or auto'
    required: false
    default: 'auto'
  anthropic-api-key:
    description: 'Anthropic API key for Claude AI analysis'
    required: false
    default: ''
  openai-api-key:
    description: 'OpenAI API key for GPT-4 analysis'
    required: false
    default: ''
  ollama-endpoint:
    description: 'Ollama endpoint URL for local LLM (e.g., http://localhost:11434)'
    required: false
    default: ''
  model:
    description: 'AI model to use (e.g., claude-sonnet-4, gpt-4, llama3)'
    required: false
    default: 'auto'
  
  # Multi-Agent Configuration
  multi-agent-mode:
    description: 'Enable multi-agent mode: single, sequential, or parallel'
    required: false
    default: 'single'

  # Exploit Analysis Configuration (Aardvark Mode)
  enable-exploit-analysis:
    description: 'Enable exploit chain analysis and exploitability assessment (Aardvark mode)'
    required: false
    default: 'true'

  generate-security-tests:
    description: 'Auto-generate security tests for discovered vulnerabilities'
    required: false
    default: 'true'

  exploitability-threshold:
    description: 'Block merge if exploitability is at this level or higher (trivial, moderate, complex, theoretical, none)'
    required: false
    default: 'trivial'

  # Cost/Latency Guardrails
  only-changed:
    description: 'Only analyze changed files (PR mode)'
    required: false
    default: 'false'
  include-paths:
    description: 'Glob patterns to include (comma-separated)'
    required: false
    default: ''
  exclude-paths:
    description: 'Glob patterns to exclude (comma-separated)'
    required: false
    default: '.github/**,node_modules/**,*.lock,package-lock.json'
  max-file-size:
    description: 'Max file size in bytes'
    required: false
    default: '50000'
  max-files:
    description: 'Max files to analyze'
    required: false
    default: '50'
  max-tokens:
    description: 'Max tokens per LLM call'
    required: false
    default: '8000'
  cost-limit:
    description: 'Max cost in USD per run'
    required: false
    default: '1.0'

outputs:
  review-completed:
    description: 'Whether the review completed successfully'
    value: ${{ steps.code-review.outputs.completed }}
  blockers-found:
    description: 'Number of merge blockers found'
    value: ${{ steps.code-review.outputs.blockers }}
  suggestions-found:
    description: 'Number of suggestions found'
    value: ${{ steps.code-review.outputs.suggestions }}
  report-path:
    description: 'Path to the generated report'
    value: ${{ steps.code-review.outputs.report-path }}
  sarif-path:
    description: 'Path to SARIF file for Code Scanning'
    value: ${{ steps.code-review.outputs.sarif-path }}
  json-path:
    description: 'Path to structured JSON results'
    value: ${{ steps.code-review.outputs.json-path }}
  cost-estimate:
    description: 'Estimated cost in USD'
    value: ${{ steps.code-review.outputs.cost-estimate }}
  files-analyzed:
    description: 'Number of files analyzed'
    value: ${{ steps.code-review.outputs.files-analyzed }}
  duration-seconds:
    description: 'Analysis duration in seconds'
    value: ${{ steps.code-review.outputs.duration-seconds }}

  # Exploit Analysis Outputs (Aardvark Mode)
  exploitability-trivial:
    description: 'Number of trivially exploitable vulnerabilities found'
    value: ${{ steps.code-review.outputs.exploitability-trivial }}

  exploitability-moderate:
    description: 'Number of moderately exploitable vulnerabilities found'
    value: ${{ steps.code-review.outputs.exploitability-moderate }}

  exploitability-complex:
    description: 'Number of complex exploitability vulnerabilities found'
    value: ${{ steps.code-review.outputs.exploitability-complex }}

  exploit-chains-found:
    description: 'Number of exploit chains identified'
    value: ${{ steps.code-review.outputs.exploit-chains-found }}

  tests-generated:
    description: 'Number of security test files generated'
    value: ${{ steps.code-review.outputs.tests-generated }}

runs:
  using: 'composite'
  steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        # Cache disabled - repositories may not have lock files

    - name: Install Agent OS
      shell: bash
      run: |
        echo "Setting up Agent OS Code Reviewer system..."
        
        # Create Agent OS directory structure
        mkdir -p $HOME/.agent-os/{scripts,profiles,standards}
        
        # Copy our scripts from the action repository to the Agent OS directory
        if [ -d "$GITHUB_ACTION_PATH/scripts" ]; then
          cp -r $GITHUB_ACTION_PATH/scripts/* $HOME/.agent-os/scripts/ 2>/dev/null || echo "Note: No scripts to copy"
          echo "Scripts copied from action repository"
        fi
        
        if [ -d "$GITHUB_ACTION_PATH/profiles" ]; then
          cp -r $GITHUB_ACTION_PATH/profiles/* $HOME/.agent-os/profiles/ 2>/dev/null || echo "Note: No profiles to copy"
          echo "Profiles copied from action repository"
        fi
        
        # Make scripts executable
        chmod +x $HOME/.agent-os/scripts/*.sh 2>/dev/null || true
        chmod +x $HOME/.agent-os/scripts/*.py 2>/dev/null || true
        
        # Verify installation
        if [ ! -d "$HOME/.agent-os" ]; then
          echo "❌ Agent OS installation failed - directory not created"
          exit 1
        fi
        
        if [ ! -d "$HOME/.agent-os/scripts" ]; then
          echo "⚠️  Warning: scripts directory not found"
        fi
        
        echo "✅ Agent OS Code Reviewer system installed successfully"

    - name: Install Code Reviewer System
      shell: bash
      run: |
        echo "Installing code reviewer system..."
        
        # Create directories
        mkdir -p $HOME/.agent-os/profiles/default/agents
        mkdir -p $HOME/.agent-os/profiles/default/workflows/review
        mkdir -p $HOME/.agent-os/profiles/default/standards/review
        mkdir -p $HOME/.agent-os/profiles/default/commands/audit-codebase/multi-agent
        mkdir -p $HOME/.agent-os/profiles/default/commands/review-changes/multi-agent
        mkdir -p $HOME/.agent-os/profiles/default/commands/security-scan/multi-agent
        mkdir -p $HOME/.agent-os/profiles/default/roles
        
        # Copy code reviewer files from this repository
        if [ -d "$GITHUB_ACTION_PATH/profiles/default/agents" ]; then
          cp -r $GITHUB_ACTION_PATH/profiles/default/agents/* $HOME/.agent-os/profiles/default/agents/
          echo "Agents copied successfully"
        fi
        
        if [ -d "$GITHUB_ACTION_PATH/profiles/default/workflows/review" ]; then
          cp -r $GITHUB_ACTION_PATH/profiles/default/workflows/review $HOME/.agent-os/profiles/default/workflows/
          echo "Workflows copied successfully"
        fi
        
        if [ -d "$GITHUB_ACTION_PATH/profiles/default/standards/review" ]; then
          cp -r $GITHUB_ACTION_PATH/profiles/default/standards/review $HOME/.agent-os/profiles/default/standards/
          echo "Standards copied successfully"
        fi
        
        if [ -d "$GITHUB_ACTION_PATH/profiles/default/commands" ]; then
          cp -r $GITHUB_ACTION_PATH/profiles/default/commands/audit-codebase $HOME/.agent-os/profiles/default/commands/
          cp -r $GITHUB_ACTION_PATH/profiles/default/commands/review-changes $HOME/.agent-os/profiles/default/commands/
          cp -r $GITHUB_ACTION_PATH/profiles/default/commands/security-scan $HOME/.agent-os/profiles/default/commands/
          echo "Commands copied successfully"
        fi
        
        # Copy AI audit script
        if [ -f "$GITHUB_ACTION_PATH/scripts/run_ai_audit.py" ]; then
          mkdir -p $HOME/.agent-os/scripts
          cp $GITHUB_ACTION_PATH/scripts/run_ai_audit.py $HOME/.agent-os/scripts/
          chmod +x $HOME/.agent-os/scripts/run_ai_audit.py
          echo "AI audit script copied successfully"
        else
          echo "Warning: AI audit script not found at $GITHUB_ACTION_PATH/scripts/run_ai_audit.py"
        fi
        
        if [ -f "$GITHUB_ACTION_PATH/profiles/default/roles/reviewers.yml" ]; then
          cp $GITHUB_ACTION_PATH/profiles/default/roles/reviewers.yml $HOME/.agent-os/profiles/default/roles/
          echo "Roles copied successfully"
        fi
        
        echo "Code reviewer system installed successfully"

    - name: Install Agent OS to Project
      shell: bash
      run: |
        echo "Setting up Agent OS in project directory..."
        cd "${{ inputs.project-path }}"
        
        # Create project-level Agent OS directory
        mkdir -p .agent-os/{config,reports}
        
        # Copy configuration files
        cp -r $HOME/.agent-os/profiles/default/standards .agent-os/ 2>/dev/null || true
        
        echo "Project Agent OS setup completed"

    - name: Detect Project Type
      id: detect-type
      shell: bash
      run: |
        echo "Detecting project type..."
        cd "${{ inputs.project-path }}"
        
        if [ "${{ inputs.project-type }}" = "auto" ]; then
          # Fallback to backend-api if detection script doesn't exist
          if [ -f "$HOME/.agent-os/scripts/detect-project-type.sh" ]; then
            PROJECT_TYPE=$($HOME/.agent-os/scripts/detect-project-type.sh .)
            echo "Auto-detected project type: $PROJECT_TYPE"
          else
            PROJECT_TYPE="backend-api"
            echo "Detection script not found, defaulting to: $PROJECT_TYPE"
          fi
        else
          PROJECT_TYPE="${{ inputs.project-type }}"
          echo "Using manual project type: $PROJECT_TYPE"
        fi
        
        echo "project-type=$PROJECT_TYPE" >> $GITHUB_OUTPUT
        echo "Detected project type: $PROJECT_TYPE"

    - name: Run Code Review
      id: code-review
      shell: bash
      env:
        INPUT_AI_PROVIDER: ${{ inputs.ai-provider }}
        ANTHROPIC_API_KEY: ${{ inputs.anthropic-api-key }}
        OPENAI_API_KEY: ${{ inputs.openai-api-key }}
        OLLAMA_ENDPOINT: ${{ inputs.ollama-endpoint }}
        INPUT_MODEL: ${{ inputs.model }}
        INPUT_MULTI_AGENT_MODE: ${{ inputs.multi-agent-mode }}
        INPUT_ONLY_CHANGED: ${{ inputs.only-changed }}
        INPUT_INCLUDE_PATHS: ${{ inputs.include-paths }}
        INPUT_EXCLUDE_PATHS: ${{ inputs.exclude-paths }}
        INPUT_MAX_FILE_SIZE: ${{ inputs.max-file-size }}
        INPUT_MAX_FILES: ${{ inputs.max-files }}
        INPUT_MAX_TOKENS: ${{ inputs.max-tokens }}
        INPUT_COST_LIMIT: ${{ inputs.cost-limit }}
        INPUT_FAIL_ON: ${{ inputs.fail-on }}
        # Exploit Analysis Configuration (Aardvark Mode)
        ENABLE_EXPLOIT_ANALYSIS: ${{ inputs.enable-exploit-analysis }}
        GENERATE_SECURITY_TESTS: ${{ inputs.generate-security-tests }}
        EXPLOITABILITY_THRESHOLD: ${{ inputs.exploitability-threshold }}
      run: |
        echo "🤖 Running AI-Powered Code Review..."
        cd "${{ inputs.project-path }}"
        
        # Create reviews directory
        mkdir -p .agent-os/reviews
        
        # Install Python dependencies
        echo "📦 Installing dependencies..."
        pip install -q anthropic openai tenacity
        
        # Run AI-powered audit with guardrails
        echo "🧠 Analyzing codebase with AI..."
        echo "⚙️  Configuration:"
        echo "   - Only changed: ${{ inputs.only-changed }}"
        echo "   - Max files: ${{ inputs.max-files }}"
        echo "   - Cost limit: \$${{ inputs.cost-limit }}"
        
        python3 $HOME/.agent-os/scripts/run_ai_audit.py "$(pwd)" "${{ inputs.review-type }}"
        
        # Check if analysis succeeded
        REPORT_FILE=".agent-os/reviews/${{ inputs.review-type }}-report.md"
        SARIF_FILE=".agent-os/reviews/results.sarif"
        JSON_FILE=".agent-os/reviews/results.json"
        METRICS_FILE=".agent-os/reviews/metrics.json"
        
        if [ ! -f "$REPORT_FILE" ]; then
          echo "❌ AI analysis failed - no report generated"
          exit 2
        fi
        
        # Extract metrics from JSON files
        if [ -f "$METRICS_FILE" ]; then
          COST=$(jq -r '.cost_usd' "$METRICS_FILE" 2>/dev/null || echo "0.00")
          FILES=$(jq -r '.files_reviewed' "$METRICS_FILE" 2>/dev/null || echo "0")
          DURATION=$(jq -r '.duration_seconds' "$METRICS_FILE" 2>/dev/null || echo "0")
          BLOCKERS=$(jq -r '.findings.critical + .findings.high' "$METRICS_FILE" 2>/dev/null || echo "0")
          SUGGESTIONS=$(jq -r '.findings.medium + .findings.low' "$METRICS_FILE" 2>/dev/null || echo "0")
          # Extract Aardvark mode metrics
          EXPLOIT_TRIVIAL=$(jq -r '.exploitability.trivial' "$METRICS_FILE" 2>/dev/null || echo "0")
          EXPLOIT_MODERATE=$(jq -r '.exploitability.moderate' "$METRICS_FILE" 2>/dev/null || echo "0")
          EXPLOIT_COMPLEX=$(jq -r '.exploitability.complex' "$METRICS_FILE" 2>/dev/null || echo "0")
          EXPLOIT_CHAINS=$(jq -r '.exploit_chains_found' "$METRICS_FILE" 2>/dev/null || echo "0")
          TESTS_GENERATED=$(jq -r '.tests_generated' "$METRICS_FILE" 2>/dev/null || echo "0")
        else
          # Fallback: count from report
          BLOCKERS=$(grep -c "\[CRITICAL\]\|\[BLOCKER\]" "$REPORT_FILE" || echo "0")
          SUGGESTIONS=$(grep -c "\[HIGH\]\|\[MEDIUM\]\|\[SUGGESTION\]" "$REPORT_FILE" || echo "0")
          COST="0.00"
          FILES="0"
          DURATION="0"
          EXPLOIT_TRIVIAL="0"
          EXPLOIT_MODERATE="0"
          EXPLOIT_COMPLEX="0"
          EXPLOIT_CHAINS="0"
          TESTS_GENERATED="0"
        fi

        # Ensure all variables have valid values (prevent empty strings that cause format errors)
        BLOCKERS="${BLOCKERS:-0}"
        SUGGESTIONS="${SUGGESTIONS:-0}"
        COST="${COST:-0.00}"
        FILES="${FILES:-0}"
        DURATION="${DURATION:-0}"
        EXPLOIT_TRIVIAL="${EXPLOIT_TRIVIAL:-0}"
        EXPLOIT_MODERATE="${EXPLOIT_MODERATE:-0}"
        EXPLOIT_COMPLEX="${EXPLOIT_COMPLEX:-0}"
        EXPLOIT_CHAINS="${EXPLOIT_CHAINS:-0}"
        TESTS_GENERATED="${TESTS_GENERATED:-0}"

        # Write all outputs atomically to prevent format errors
        {
          echo "completed=true"
          echo "blockers=$BLOCKERS"
          echo "suggestions=$SUGGESTIONS"
          echo "report-path=$REPORT_FILE"
          echo "sarif-path=$SARIF_FILE"
          echo "json-path=$JSON_FILE"
          echo "cost-estimate=$COST"
          echo "files-analyzed=$FILES"
          echo "duration-seconds=$DURATION"
          echo "exploitability-trivial=$EXPLOIT_TRIVIAL"
          echo "exploitability-moderate=$EXPLOIT_MODERATE"
          echo "exploitability-complex=$EXPLOIT_COMPLEX"
          echo "exploit-chains-found=$EXPLOIT_CHAINS"
          echo "tests-generated=$TESTS_GENERATED"
        } >> $GITHUB_OUTPUT

        echo "✅ Code review completed successfully"

    # Upload artifacts - pinned by SHA
    - name: Upload Review Reports
      if: ${{ inputs.upload-reports == 'true' }}
      uses: actions/upload-artifact@50769540e7f4bd5e21e526ee35c689e35e0d6874  # v4.4.0
      with:
        name: code-review-reports-${{ github.run_id }}-${{ github.run_attempt }}
        path: ${{ inputs.project-path }}/.agent-os/reviews/
        retention-days: 30

    # Create PR - pinned by SHA
    - name: Create PR with Audit Findings
      if: ${{ github.event_name != 'pull_request' && steps.code-review.outputs.blockers > 0 }}
      uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea  # v7.0.1
      env:
        GITHUB_TOKEN: ${{ github.token }}
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          // Read the audit report
          const reportPath = '${{ inputs.project-path }}/.agent-os/reviews/${{ inputs.review-type }}-report.md';
          let reportContent = '';
          
          if (fs.existsSync(reportPath)) {
            reportContent = fs.readFileSync(reportPath, 'utf8');
          } else {
            console.log('No report found at:', reportPath);
            return;
          }
          
          // Extract key findings for PR title and description
          const blockerCount = ${{ steps.code-review.outputs.blockers }};
          const suggestionCount = ${{ steps.code-review.outputs.suggestions }};
          
          // Generate branch name with timestamp
          const timestamp = new Date().toISOString().split('T')[0].replace(/-/g, '');
          const branchName = `audit/code-review-findings-${timestamp}`;
          
          // Check for existing PRs with similar findings
          const { data: existingPRs } = await github.rest.pulls.list({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            head: `${context.repo.owner}:${branchName}`
          });
          
          // Also check for any open audit PRs
          const { data: allOpenPRs } = await github.rest.pulls.list({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open'
          });
          
          const auditPRs = allOpenPRs.filter(pr => 
            pr.head.ref.startsWith('audit/') && 
            pr.title.includes('Code Review Findings')
          );
          
          // If there's an existing OPEN audit PR, update it instead of creating a new one
          if (auditPRs.length > 0) {
            console.log(`Found ${auditPRs.length} existing OPEN audit PR(s). Updating the most recent one...`);
            
            // Update the most recent audit PR
            const latestPR = auditPRs[0];
            
            // Add a comment with new findings
            const updateBody = [
              '## 🔄 Updated Code Review Findings',
              '',
              `**Run Date:** ${new Date().toISOString()}`,
              `**Commit:** ${context.sha}`,
              `**Blockers Found:** ${blockerCount}`,
              `**Suggestions:** ${suggestionCount}`,
              '',
              '---',
              '',
              reportContent,
              '',
              '---',
              '',
              '**Note:** This is an automated update from the latest code review run.',
              `**Artifact:** code-review-reports-${context.runId}-${context.runAttempt}`,
              `**Run URL:** ${context.payload.repository.html_url}/actions/runs/${context.runId}`
            ].join('\n');
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: latestPR.number,
              body: updateBody
            });
            
            console.log(`✅ Updated existing PR #${latestPR.number} with new findings`);
            return; // Exit early - don't create a new PR
          }
          
          // No existing OPEN PR found, create a new one
          console.log('No existing OPEN audit PR found. Creating new PR...');
          
          // Get current branch
          const currentBranch = context.ref.replace('refs/heads/', '');
          
          // Get current commit
          const { data: refData } = await github.rest.git.getRef({
            owner: context.repo.owner,
            repo: context.repo.repo,
            ref: `heads/${currentBranch}`
          });
          
          // Create a commit with the audit report
          const reportFileName = `audit-reports/code-review-${timestamp}.md`;
          const reportContentBase64 = Buffer.from(reportContent).toString('base64');
          
          // Create a blob for the report
          const { data: blob } = await github.rest.git.createBlob({
            owner: context.repo.owner,
            repo: context.repo.repo,
            content: reportContentBase64,
            encoding: 'base64'
          });
          
          // Get the current tree
          const { data: currentCommit } = await github.rest.git.getCommit({
            owner: context.repo.owner,
            repo: context.repo.repo,
            commit_sha: refData.object.sha
          });
          
          // Create a new tree with the report file
          const { data: newTree } = await github.rest.git.createTree({
            owner: context.repo.owner,
            repo: context.repo.repo,
            base_tree: currentCommit.tree.sha,
            tree: [
              {
                path: reportFileName,
                mode: '100644',
                type: 'blob',
                sha: blob.sha
              }
            ]
          });
          
          // Create a new commit
          const { data: newCommit } = await github.rest.git.createCommit({
            owner: context.repo.owner,
            repo: context.repo.repo,
            message: `Add automated code review findings\n\nBlockers: ${blockerCount}\nSuggestions: ${suggestionCount}\n\nGenerated by Agent OS Code Reviewer`,
            tree: newTree.sha,
            parents: [refData.object.sha]
          });
          
          // Create or update branch pointing to the new commit
          try {
            await github.rest.git.createRef({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: `refs/heads/${branchName}`,
              sha: newCommit.sha
            });
          } catch (error) {
            if (error.status === 422) {
              // Branch already exists, update it
              await github.rest.git.updateRef({
                owner: context.repo.owner,
                repo: context.repo.repo,
                ref: `heads/${branchName}`,
                sha: newCommit.sha,
                force: true
              });
            } else {
              throw error;
            }
          }
          
          // Check if PR already exists for this branch
          const { data: existingBranchPRs } = await github.rest.pulls.list({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            head: `${context.repo.owner}:${branchName}`,
            base: currentBranch
          });
          
          if (existingBranchPRs.length > 0) {
            console.log(`PR already exists for branch ${branchName}. Updating it...`);
            const existingPR = existingBranchPRs[0];
            
            // Add a comment with new findings
            const updateBody = [
              '## 🔄 Updated Code Review Findings',
              '',
              `**Run Date:** ${new Date().toISOString()}`,
              `**Commit:** ${newCommit.sha}`,
              `**Blockers Found:** ${blockerCount}`,
              `**Suggestions:** ${suggestionCount}`,
              '',
              '---',
              '',
              reportContent,
              '',
              '---',
              '',
              '**Note:** This is an automated update from the latest code review run.',
              `**Artifact:** code-review-reports-${context.runNumber}`,
              `**Run URL:** ${context.payload.repository.html_url}/actions/runs/${context.runId}`
            ].join('\n');
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: existingPR.number,
              body: updateBody
            });
            
            console.log(`Updated existing PR #${existingPR.number}`);
            return;
          }
          
          // Create new PR
          const prTitle = `🔍 Code Review Findings: ${blockerCount} Blocker(s), ${suggestionCount} Suggestion(s)`;
          const prBody = [
            '## 📊 Automated Code Review Report',
            '',
            `**Review Date:** ${new Date().toISOString()}`,
            `**Repository:** ${context.repo.owner}/${context.repo.repo}`,
            `**Branch:** ${currentBranch}`,
            `**Commit:** ${newCommit.sha}`,
            `**Review Type:** ${{ inputs.review-type }}`,
            '',
            '### 📈 Summary',
            `- **Merge Blockers:** ${blockerCount} (Must fix before merge)`,
            `- **Suggestions:** ${suggestionCount} (Recommended improvements)`,
            '',
            '---',
            '',
            reportContent,
            '',
            '---',
            '',
            '### 📁 Artifacts',
            `- **Report Artifact:** code-review-reports-${context.runNumber}`,
            `- **Run URL:** ${context.payload.repository.html_url}/actions/runs/${context.runId}`,
            '',
            '### 🤖 Automated Review',
            'This PR was automatically created by the Agent OS Code Reviewer system.',
            'Please review the findings and address the merge blockers before merging.',
            '',
            '**Note:** If you fix the issues, this PR will be automatically updated on the next review run.'
          ].join('\n');
          
          const { data: pr } = await github.rest.pulls.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: prTitle,
            head: branchName,
            base: currentBranch,
            body: prBody
          });
          
          console.log(`Created PR #${pr.number}: ${pr.html_url}`);
          
          // Add labels
          await github.rest.issues.addLabels({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: pr.number,
            labels: ['automated-review', 'code-quality', 'security']
          });

    # Comment on PR - pinned by SHA
    - name: Comment on PR
      if: ${{ github.event_name == 'pull_request' && inputs.comment-on-pr == 'true' }}
      uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea  # v7.0.1
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          // Read the review report
          const reportPath = '${{ inputs.project-path }}/.agent-os/reviews/review-report.md';
          let reportContent = '';
          
          if (fs.existsSync(reportPath)) {
            reportContent = fs.readFileSync(reportPath, 'utf8');
          } else {
            reportContent = '## Code Review Report\n\nReview completed successfully. Please check the artifacts for detailed reports.';
          }
          
          // Create PR comment
          const comment = `## 🔍 Code Review Report
          
          ${reportContent}
          
          ---
          
          **Review completed by:** Code Reviewer System
          **Review date:** ${new Date().toISOString()}
          **Repository:** ${context.repo.owner}/${context.repo.repo}
          **Branch:** ${context.ref.replace('refs/heads/', '')}
          **Commit:** ${context.sha}
          
          📁 **Detailed reports available in artifacts:** code-review-reports-${context.runNumber}`;
          
          // Post comment
          await github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

    - name: Send Slack Notification
      if: ${{ inputs.slack-webhook-url != '' }}
      shell: bash
      env:
        SLACK_WEBHOOK: ${{ inputs.slack-webhook-url }}
        NOTIFY_ON: ${{ inputs.notify-on }}
        BLOCKERS: ${{ steps.code-review.outputs.blockers }}
        SUGGESTIONS: ${{ steps.code-review.outputs.suggestions }}
        COST: ${{ steps.code-review.outputs.cost-estimate }}
        FILES: ${{ steps.code-review.outputs.files-analyzed }}
      run: |
        SHOULD_NOTIFY=false
        
        case "$NOTIFY_ON" in
          always)
            SHOULD_NOTIFY=true
            ;;
          on-failure)
            if [ "${{ steps.code-review.outputs.completed }}" != "true" ]; then
              SHOULD_NOTIFY=true
            fi
            ;;
          on-blockers)
            if [ "$BLOCKERS" -gt "0" ]; then
              SHOULD_NOTIFY=true
            fi
            ;;
          never)
            SHOULD_NOTIFY=false
            ;;
        esac
        
        if [ "$SHOULD_NOTIFY" = "true" ]; then
          STATUS_ICON="✅"
          STATUS_COLOR="good"
          if [ "$BLOCKERS" -gt "0" ]; then
            STATUS_ICON="🔴"
            STATUS_COLOR="danger"
          fi
          
          PAYLOAD=$(cat <<EOF
        {
          "attachments": [{
            "color": "$STATUS_COLOR",
            "title": "$STATUS_ICON Agent OS Code Review Complete",
            "text": "Repository: ${{ github.repository }}",
            "fields": [
              {"title": "Blockers", "value": "$BLOCKERS", "short": true},
              {"title": "Suggestions", "value": "$SUGGESTIONS", "short": true},
              {"title": "Files Analyzed", "value": "$FILES", "short": true},
              {"title": "Cost", "value": "\$$COST", "short": true}
            ],
            "footer": "Agent OS",
            "footer_icon": "https://github.com/securedotcom.png",
            "ts": $(date +%s),
            "actions": [{
              "type": "button",
              "text": "View Report",
              "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }]
          }]
        }
        EOF
          )
          
          curl -X POST "$SLACK_WEBHOOK" \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD"
          
          echo "📢 Slack notification sent"
        fi

    - name: Fail on Blockers
      if: ${{ inputs.fail-on-blockers == 'true' && steps.code-review.outputs.blockers > 0 }}
      shell: bash
      run: |
        echo "❌ Merge blockers found: ${{ steps.code-review.outputs.blockers }}"
        echo "Please fix all merge blockers before merging."
        exit 1





