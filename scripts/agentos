#!/usr/bin/env python3
"""
Agent-OS CLI
Main command-line interface for security control plane
"""

import sys
import argparse
from pathlib import Path

# Add scripts dir to path
SCRIPT_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPT_DIR))


def cmd_normalize(args):
    """Normalize security tool outputs"""
    from normalizer import UnifiedNormalizer
    import json
    
    normalizer = UnifiedNormalizer()
    
    # Load tool outputs
    tool_outputs = {}
    for input_file in args.inputs:
        path = Path(input_file)
        
        # Detect tool from filename
        tool = None
        if 'semgrep' in path.name or path.suffix == '.sarif':
            tool = 'semgrep'
        elif 'trivy' in path.name:
            tool = 'trivy'
        elif 'trufflehog' in path.name:
            tool = 'trufflehog'
        elif 'gitleaks' in path.name:
            tool = 'gitleaks'
        elif 'checkov' in path.name:
            tool = 'checkov'
        else:
            print(f"‚ö†Ô∏è  Warning: Could not detect tool from {path.name}, skipping")
            continue
        
        with open(path) as f:
            tool_outputs[tool] = json.load(f)
    
    # Normalize
    print(f"üìä Normalizing {len(tool_outputs)} tool outputs...")
    findings = normalizer.normalize_all(tool_outputs)
    
    print(f"‚úÖ Normalized {len(findings)} findings")
    
    # Output
    output_data = {
        'findings': [f.to_dict() for f in findings],
        'summary': {
            'total': len(findings),
            'by_severity': {
                'critical': sum(1 for f in findings if f.severity == 'critical'),
                'high': sum(1 for f in findings if f.severity == 'high'),
                'medium': sum(1 for f in findings if f.severity == 'medium'),
                'low': sum(1 for f in findings if f.severity == 'low'),
            },
            'by_category': {}
        }
    }
    
    # Write output
    with open(args.output, 'w') as f:
        json.dump(output_data, f, indent=2)
    
    print(f"üìù Wrote findings to {args.output}")
    
    # Print summary
    print("\n" + "="*60)
    print("SUMMARY")
    print("="*60)
    for severity, count in output_data['summary']['by_severity'].items():
        if count > 0:
            print(f"  {severity.upper()}: {count}")


def cmd_gate(args):
    """Evaluate policy gate"""
    from gate import PolicyGate
    import json

    # Load findings
    with open(args.input) as f:
        data = json.load(f)

    findings = data if isinstance(data, list) else data.get('findings', [])

    # Prepare metadata
    metadata = None
    if args.stage == 'release':
        metadata = {
            'sbom_present': args.sbom_present,
            'signature_verified': args.signature_verified,
            'provenance_present': args.provenance_present
        }

    # Evaluate
    gate = PolicyGate()
    decision = gate.evaluate(args.stage, findings, metadata)

    # Print
    gate.print_decision(decision)

    # Exit
    sys.exit(0 if decision['decision'] == 'pass' else 1)


def cmd_feedback(args):
    """Record or view user feedback on findings"""
    from feedback_collector import FeedbackCollector

    collector = FeedbackCollector()

    if args.action == 'record':
        # Record feedback
        success = collector.record_feedback(
            finding_id=args.finding_id,
            feedback=args.mark,
            reason=args.reason
        )

        if success:
            print(f"‚úÖ Recorded feedback: {args.mark.upper()} for finding {args.finding_id}")
        else:
            print("‚ùå Failed to record feedback")
            sys.exit(1)

    elif args.action == 'stats':
        # Show stats
        stats = collector.get_feedback_stats()

        print("\n" + "=" * 60)
        print("FEEDBACK STATISTICS")
        print("=" * 60)
        print(f"Total Feedback:     {stats.get('total_feedback', 0)}")
        print(f"True Positives:     {stats.get('true_positives', 0)} ({stats.get('tp_rate', 0):.1f}%)")
        print(f"False Positives:    {stats.get('false_positives', 0)} ({stats.get('fp_rate', 0):.1f}%)")

        if stats.get("by_scanner"):
            print(f"\nBy Scanner:")
            for scanner, scanner_stats in stats["by_scanner"].items():
                fp_rate = (scanner_stats["fp"] / scanner_stats["total"] * 100) if scanner_stats["total"] > 0 else 0
                print(f"  {scanner:20s}: {scanner_stats['total']:3d} total, "
                      f"{scanner_stats['fp']:3d} FP ({fp_rate:.0f}%)")

        print("=" * 60 + "\n")


def cmd_dashboard(args):
    """Launch observability dashboard"""
    import subprocess

    dashboard_path = Path(__file__).parent / 'dashboard' / 'observability_dashboard.py'

    if not dashboard_path.exists():
        print(f"‚ùå Dashboard not found: {dashboard_path}")
        sys.exit(1)

    print("üöÄ Launching Agent-OS Observability Dashboard...")
    print(f"üìä Opening at http://localhost:8501")
    print("\nüí° Tip: Press Ctrl+C to stop the dashboard\n")

    try:
        # Launch Streamlit
        subprocess.run([
            "streamlit", "run",
            str(dashboard_path),
            "--server.port", "8501",
            "--server.headless", "true"
        ])
    except KeyboardInterrupt:
        print("\n\n‚úÖ Dashboard stopped")
    except FileNotFoundError:
        print("\n‚ùå Streamlit not installed. Install with:")
        print("   pip install streamlit plotly pandas")
        sys.exit(1)


def cmd_api_security(args):
    """Run API security testing"""
    from api_security_scanner import APISecurityScanner

    scanner = APISecurityScanner(repo_path=args.path or ".")
    findings = scanner.scan()

    # Print summary
    print(f"\nüõ°Ô∏è API Security Scan Results:")
    print(f"   Endpoints discovered: {len(scanner.endpoints)}")
    print(f"   Vulnerabilities found: {len(findings)}")

    # Group by severity
    by_severity = {}
    for f in findings:
        severity = f.get("severity", "UNKNOWN")
        by_severity[severity] = by_severity.get(severity, 0) + 1

    for sev, count in sorted(by_severity.items()):
        print(f"   {sev}: {count}")


def cmd_dast(args):
    """Run DAST scan"""
    from dast_scanner import DASTScanner

    if not args.target:
        print("‚ùå Error: --target URL required")
        sys.exit(1)

    scanner = DASTScanner(
        target_url=args.target,
        openapi_spec=args.openapi
    )

    config = {
        "severity": args.severity or "critical,high,medium",
        "timeout": args.timeout or 300
    }

    findings = scanner.scan(config)

    print(f"\nüîç DAST Scan Results:")
    print(f"   Target: {args.target}")
    print(f"   Vulnerabilities: {len(findings)}")


def cmd_correlate(args):
    """Correlate SAST and DAST findings"""
    from sast_dast_correlator import SASTDASTCorrelator
    import json

    # Load findings
    with open(args.sast) as f:
        sast_findings = json.load(f)
    with open(args.dast) as f:
        dast_findings = json.load(f)

    correlator = SASTDASTCorrelator()
    results = correlator.correlate(sast_findings, dast_findings)

    # Print results
    print(f"\nüîó SAST-DAST Correlation Results:")
    confirmed = sum(1 for r in results if r.status.value == "confirmed")
    print(f"   Confirmed exploitable: {confirmed}")
    print(f"   Total analyzed: {len(results)}")


def cmd_generate_tests(args):
    """Generate security test suite"""
    from security_test_generator import SecurityTestGenerator
    import json

    with open(args.findings) as f:
        findings = json.load(f)

    generator = SecurityTestGenerator()
    suite = generator.generate_test_suite(findings, args.output or "tests/security/")

    print(f"\nüß™ Generated Security Tests:")
    print(f"   Language: {suite.language}")
    print(f"   Framework: {suite.framework}")
    print(f"   Tests: {len(suite.tests)}")


def main():
    parser = argparse.ArgumentParser(
        description="Agent-OS Security Control Plane",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Normalize scanner outputs
  agentos normalize --inputs semgrep.sarif trivy.json --output findings.json

  # Evaluate PR gate
  agentos gate --stage pr --input findings.json

  # Evaluate release gate
  agentos gate --stage release --input findings.json --sbom-present --signature-verified

  # Record feedback on finding
  agentos feedback record finding-123 --mark fp --reason "Test fixture file"

  # Show feedback statistics
  agentos feedback stats

  # Launch observability dashboard
  agentos dashboard

  # Run API security scan
  agentos api-security --path /path/to/repo

  # Run DAST scan
  agentos dast --target https://api.example.com --openapi openapi.yaml

  # Correlate SAST and DAST findings
  agentos correlate --sast sast-findings.json --dast dast-findings.json

  # Generate security tests
  agentos generate-tests --findings findings.json --output tests/security/
"""
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Normalize command
    parser_normalize = subparsers.add_parser('normalize', help='Normalize security tool outputs')
    parser_normalize.add_argument('--inputs', nargs='+', required=True, help='Input files from security tools')
    parser_normalize.add_argument('--output', required=True, help='Output JSON file')
    parser_normalize.set_defaults(func=cmd_normalize)
    
    # Gate command
    parser_gate = subparsers.add_parser('gate', help='Evaluate policy gate')
    parser_gate.add_argument('--stage', required=True, choices=['pr', 'release'], help='Gate stage')
    parser_gate.add_argument('--input', required=True, help='Findings JSON file')
    parser_gate.add_argument('--sbom-present', action='store_true', help='SBOM present')
    parser_gate.add_argument('--signature-verified', action='store_true', help='Signature verified')
    parser_gate.add_argument('--provenance-present', action='store_true', help='Provenance present')
    parser_gate.set_defaults(func=cmd_gate)

    # Feedback command
    parser_feedback = subparsers.add_parser('feedback', help='Manage user feedback on findings')
    feedback_subparsers = parser_feedback.add_subparsers(dest='action', help='Feedback action')

    # Record feedback
    record_feedback = feedback_subparsers.add_parser('record', help='Record feedback for a finding')
    record_feedback.add_argument('finding_id', help='Finding ID')
    record_feedback.add_argument('--mark', choices=['tp', 'fp'], required=True,
                                 help='Mark as true positive (tp) or false positive (fp)')
    record_feedback.add_argument('--reason', required=True, help='Reason for feedback')

    # Show feedback stats
    feedback_subparsers.add_parser('stats', help='Show feedback statistics')

    parser_feedback.set_defaults(func=cmd_feedback)

    # Dashboard command
    parser_dashboard = subparsers.add_parser('dashboard', help='Launch observability dashboard')
    parser_dashboard.set_defaults(func=cmd_dashboard)

    # API Security command
    parser_api = subparsers.add_parser('api-security', help='Run API security testing')
    parser_api.add_argument('--path', help='Repository path (default: current directory)')
    parser_api.set_defaults(func=cmd_api_security)

    # DAST command
    parser_dast = subparsers.add_parser('dast', help='Run DAST scan')
    parser_dast.add_argument('--target', required=True, help='Target URL')
    parser_dast.add_argument('--openapi', help='OpenAPI spec path')
    parser_dast.add_argument('--severity', help='Severity levels (default: critical,high,medium)')
    parser_dast.add_argument('--timeout', type=int, help='Scan timeout in seconds (default: 300)')
    parser_dast.set_defaults(func=cmd_dast)

    # Correlate command
    parser_correlate = subparsers.add_parser('correlate', help='Correlate SAST and DAST findings')
    parser_correlate.add_argument('--sast', required=True, help='SAST findings JSON file')
    parser_correlate.add_argument('--dast', required=True, help='DAST findings JSON file')
    parser_correlate.set_defaults(func=cmd_correlate)

    # Generate tests command
    parser_gentests = subparsers.add_parser('generate-tests', help='Generate security test suite')
    parser_gentests.add_argument('--findings', required=True, help='Findings JSON file')
    parser_gentests.add_argument('--output', help='Output directory (default: tests/security/)')
    parser_gentests.set_defaults(func=cmd_generate_tests)

    args = parser.parse_args()
    
    if not hasattr(args, 'func'):
        parser.print_help()
        sys.exit(1)
    
    args.func(args)


if __name__ == '__main__':
    main()

