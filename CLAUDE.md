# CLAUDE.md - Agent-OS Security Action Context

## Project Overview

**Agent-OS Security Action** is a production-grade GitHub Action that orchestrates multiple security scanners (TruffleHog, Gitleaks, Semgrep, Trivy, Checkov) with AI-powered triage to reduce false positives and enforce security policies. It acts as a security control plane that runs in GitHub Actions, providing comprehensive security scanning with intelligent noise reduction.

Key capabilities:
- Multi-scanner orchestration with parallel execution (4 scanners: TruffleHog, Gitleaks, Semgrep, Trivy)
- AI triage using Claude/OpenAI/Ollama (Foundation-Sec-8B removed)
- 60-70% false positive reduction via ML noise scoring
- Policy enforcement via Rego
- SARIF/JSON/Markdown reporting
- Docker-based sandbox validation for exploit verification
- Intelligent caching for scanner results and AI responses
- Rich progress bars for real-time feedback

## Tech Stack

**Language:** Python 3.9+ (14,200+ lines)
**Version:** 1.0.15

**Core Dependencies:**
- `anthropic>=0.40.0` - Claude AI integration
- `openai>=1.56.0` - OpenAI GPT integration
- `semgrep>=1.100.0` - SAST scanning
- `pytm>=1.3.0` - Threat modeling (STRIDE)
- `tenacity>=9.0.0` - Retry logic
- `pyyaml>=6.0.2` - YAML processing
- `rich>=13.0.0` - Progress bars and terminal UI

**Development Tools:**
- `ruff>=0.8.0` - Linting/formatting (replaces black, pylint, isort, flake8)
- `mypy>=1.0.0` - Type checking
- `pytest>=7.0.0` - Testing framework
- `pytest-cov>=4.0.0` - Coverage reporting

**Security Scanners Integrated:**
- TruffleHog - Verified secret detection (actively used)
- Gitleaks - Pattern-based secret scanning (actively used)
- Semgrep - SAST with 2000+ rules (actively used)
- Trivy - CVE/dependency scanning (actively used)
- Checkov - IaC security (implemented but not yet integrated into main workflow)

**Removed Dependencies:**
- `boto3` / `botocore` - AWS SDK (removed with Foundation-Sec)
- Foundation-Sec-8B - Local ML model for AI triage (deprecated)

## Project Structure

```
agent-os-action/
├── scripts/                    # Core application (40+ Python modules)
│   ├── run_ai_audit.py        # Main orchestrator (2,719 lines)
│   ├── agentos                # CLI entry point
│   ├── normalizer/            # Scanner output normalization
│   ├── providers/             # AI provider integrations
│   ├── orchestrator/          # Orchestration and execution coordination
│   │   ├── base.py           # Base orchestrator interface
│   │   ├── scanner_orchestrator.py  # Scanner execution coordination
│   │   └── workflow_orchestrator.py # High-level workflow management
│   ├── scanners/              # Individual scanner implementations
│   │   ├── trufflehog_scanner.py   # TruffleHog integration
│   │   ├── checkov_scanner.py      # Checkov IaC scanner
│   │   ├── gitleaks_scanner.py     # Gitleaks secrets scanner
│   │   └── [other scanners]
│   ├── cache_manager.py       # Caching system for scanner/AI results
│   ├── progress_tracker.py    # Rich progress bar implementation
│   ├── hybrid_analyzer.py     # Multi-scanner combination
│   ├── sandbox_validator.py   # Docker exploit validation
│   └── [30+ other modules]    # Analysis, scoring, enrichment
├── .github/workflows/         # 26 CI/CD workflows
├── docs/                      # Comprehensive documentation
│   ├── adrs/                 # Architecture decision records
│   ├── architecture/         # System design docs
│   └── references/           # Scanner configuration guides
├── tests/                     # Unit and integration tests
│   ├── unit/                 # Unit test suite
│   └── integration/          # E2E workflow tests
├── policy/                    # Rego policy files
├── examples/                  # Usage examples
├── action.yml                 # GitHub Action definition (31KB)
├── Dockerfile                 # Multi-stage container build
├── pyproject.toml            # Python project config
└── requirements.txt          # Python dependencies
```

## Current Status

**Branch:** `docs/comprehensive-ai-docs-20251110`
**Base:** `main`
**Last Updated:** 2026-01-08

**Recent Work (Session 2026-01-08 - Part 2):**
1. **Parallel agent execution** - Used 5 concurrent agents to rapidly analyze and implement improvements:
   - Checkov integration analysis (4-5 hour task completed in minutes)
   - Test coverage gap analysis (identified 4 critical modules)
   - Sandbox TODO analysis (11 missing exploit templates)
   - v1.1.0 release planning (comprehensive release plan created)
   - CI/CD workflow review (23 workflows, identified 40% duplication)

2. **Checkov scanner integration** - COMPLETED:
   - Integrated into `hybrid_analyzer.py` following Semgrep/Trivy pattern
   - Added `enable_checkov` parameter (enabled by default)
   - Implemented `_run_checkov()` method for IaC scanning
   - CLI argument `--enable-checkov` added
   - **Status: 5 active scanners** - TruffleHog, Gitleaks, Semgrep, Trivy, Checkov

3. **Test coverage expansion** - COMPLETED:
   - Created `test_progress_tracker.py` - 950 lines, 69 tests (100% coverage)
   - Created `test_trufflehog_scanner.py` - 928 lines, 48 tests (100% coverage)
   - Created `test_checkov_scanner.py` - 962 lines, 50 tests (100% coverage)
   - **Total: 2,840 lines of tests, 167 test methods**

4. **CI/CD quick wins** - COMPLETED:
   - Deleted duplicate `semgrep-simple.yml` (saves 5-10 min per run)
   - Updated GitHub Actions to latest versions (v3→v4, v2→v3)
   - Security improvements and performance optimizations

5. **Documentation & release preparation**:
   - Created PR #38 to merge docs branch to main
   - Comprehensive v1.1.0 release plan created
   - All changes committed and pushed

**Previous Work (Session 2026-01-08 - Part 1):**
1. **Major production readiness commit** - Successfully merged comprehensive improvements to main:
   - Security fixes: Command injection vulnerabilities, Docker root user, path traversal protection
   - Architecture refactoring: Broke down 2,719-line god object into modular orchestrator package
   - New scanners: TruffleHog (561 lines) and Checkov (705 lines) fully implemented
   - Performance features: Intelligent caching system and real-time progress bars
   - Dependency cleanup: Removed Foundation-Sec-8B and all AWS dependencies
   - Documentation overhaul: Updated all docs to reflect actual working features
   - 41 comprehensive security tests added

**Previous Session Work:**
1. **Documentation expansion** - Added comprehensive AI-generated docs for ADRs, architecture, best practices
2. **Linting cleanup** - Fixed all ruff/pylint errors across codebase (COMPLETE)
3. **Security hardening** - Fixed CVEs, added permissions to workflows, sanitized logging (COMPLETE)
4. **CI improvements** - Fixed Gitleaks/Semgrep workflows, made OPA optional
5. **Refactoring** - Modularized scanner code, added orchestrator pattern (COMPLETE)
6. **Scanner implementations** - Added TruffleHog and Checkov scanners (COMPLETE)
7. **Foundation-Sec removal** - Removed Foundation-Sec/boto3/botocore dependencies (COMPLETE)
8. **Performance enhancements** - Added caching system and rich progress bars (COMPLETE)

**Modified Files on Current Branch:**
- `docs/adrs/0002-multi-scanner-architecture.md` - MODIFIED
- `docs/adrs/0003-ai-triage-strategy.md` - MODIFIED
- `docs/best-practices.md` - MODIFIED
- `docs/references/scanner-reference.md` - MODIFIED
- `docs/architecture/overview.md` - MODIFIED
- `docs/FAQ.md` - MODIFIED
- `README.md` - MODIFIED
- `requirements.txt` - MODIFIED (removed boto3/botocore, added rich)
- `action.yml` - MODIFIED
- `Dockerfile` - MODIFIED
- Multiple scanner and orchestrator files - MODIFIED

**Recently Added Features:**
- **Caching System** (`cache_manager.py`) - Intelligent caching for scanner results and AI responses
- **Progress Tracking** (`progress_tracker.py`) - Rich progress bars with real-time feedback
- **TruffleHog Scanner** (`trufflehog_scanner.py`) - Verified secret detection (FULLY INTEGRATED)
- **Checkov Scanner** (`checkov_scanner.py`) - Infrastructure-as-Code security scanning (FULLY INTEGRATED)
- **Orchestrator Pattern** (`orchestrator/`) - Modular workflow and scanner coordination
- **5 Active Scanners** - TruffleHog, Gitleaks, Semgrep, Trivy, Checkov (ALL INTEGRATED)
- **Comprehensive Test Suite** - 2,840+ lines of tests for progress_tracker, trufflehog_scanner, checkov_scanner (100% coverage)

## Next Steps

Based on current state and completed work:

### Immediate (Ready to Execute)
1. **Merge Documentation Branch** - ✅ PR #38 created, ready to merge to main
2. **Execute v1.1.0 Release** - Release plan complete, execute checklist and tag release
3. **CI/CD Parallelization** - Optimize workflow execution (15-20 min savings per PR)

### Short Term (Next Session)
4. **Test the New Tests** - Run pytest on new test files, ensure 100% pass rate
5. **Create Reusable Workflow** - Consolidate Python dependency installation (17 workflows affected)
6. **Performance Validation** - Benchmark caching effectiveness and progress bar UX
7. **Consolidate Branch CI Workflows** - Merge develop-ci.yml, release-ci.yml, hotfix-ci.yml (~400 lines saved)

### Medium Term (Future Enhancement)
8. **Sandbox Exploit Templates** - Implement 11 missing exploit types (XSS, SSRF, XXE, etc.) in `sandbox_integration.py:320`
9. **Cache Size Management** - Add automatic cleanup and size limits to cache_manager.py
10. **Additional Integration Tests** - Add E2E tests for full scanner workflows

### Completed ✅
- ✅ Checkov Integration - Fully integrated into hybrid_analyzer.py
- ✅ Test Coverage - 100% coverage for progress_tracker, trufflehog_scanner, checkov_scanner
- ✅ CI Quick Wins - Duplicate workflow removed, actions updated
- ✅ Release Planning - Comprehensive v1.1.0 plan created

## Code Conventions

**Python Style:**
- Line length: 120 characters
- Formatting: Ruff (configured in pyproject.toml)
- Type hints: Optional but encouraged (mypy configured)
- Docstrings: Google-style for classes/functions
- Imports: Sorted with isort (via ruff)

**Patterns:**
- Dataclasses for structured data (e.g., `UnifiedFinding`)
- Tenacity for retry logic with exponential backoff
- Logging with structured format
- Environment variables for configuration
- JSON/SARIF for structured output

**Naming:**
- Classes: PascalCase (e.g., `HeuristicScanner`)
- Functions: snake_case (e.g., `scan_file`)
- Constants: UPPER_SNAKE_CASE (e.g., `THREAT_MODELING_AVAILABLE`)
- Private methods: Leading underscore (e.g., `_find_line`)

**Error Handling:**
- Try/except for optional imports
- Graceful degradation when features unavailable
- Structured logging for errors
- Exit codes: 0 (success), 1 (failure with findings), 2+ (errors)

## How to Run

**Installation:**
```bash
# Clone and setup
git clone https://github.com/securedotcom/agent-os-action
cd agent-os-action
pip install -r requirements.txt
```

**CLI Usage:**
```bash
# Run full audit
python scripts/run_ai_audit.py \
  --project-type backend-api \
  --ai-provider anthropic \
  --output-file report.json

# Use agentos CLI
./scripts/agentos normalize --inputs semgrep.sarif trivy.json --output findings.json
./scripts/agentos gate --stage pr --input findings.json

# Available AI providers: anthropic, openai, ollama
```

**Testing:**
```bash
# Run all tests with coverage
pytest -v --cov=scripts --cov-report=term-missing

# Run specific test suite
pytest tests/unit/
pytest tests/integration/

# Linting and type checking
ruff check scripts/
ruff format scripts/
mypy scripts/*.py
```

**GitHub Action:**
```yaml
- uses: securedotcom/agent-os-action@v1
  with:
    anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}
    review-type: security
    fail-on-blockers: true
```

**Docker:**
```bash
# Build image
docker build -t agent-os .

# Run container
docker run -v $(pwd):/workspace agent-os
```

## Agent Interaction Patterns

### Overview for AI Agents

This section provides concrete examples of how AI agents should interact with Agent-OS compositionally. The system is designed for **tool composition** rather than hard-coded workflows, enabling emergent capabilities through primitive combination.

### 1. Discovering Available Capabilities

When asked "What security checks can you run for SQL injection?":

```bash
# Discover scanners with SQL injection detection
./scripts/agentos list-scanners --capability sql-injection
# Output: semgrep (cwe-89, cwe-564)

# Get details on specific scanner rules
python scripts/run_ai_audit.py --list-semgrep-rules | grep -i sql
# Output: 47 rules matching SQL injection patterns
```

### 2. Composing Custom Security Workflows

When asked "Check all user input handlers for injection vulnerabilities":

```bash
# Step 1: Find files with user input handling (example for Python/Django)
FILES=$(grep -rl 'request\.GET\|request\.POST' app/)

# Step 2: Run targeted SAST scan
python scripts/run_ai_audit.py \
  --project-type backend-api \
  --semgrep-enabled \
  --only-changed $FILES \
  --output-file injection-findings.json

# Step 3: Apply AI triage with custom context
# (Built into run_ai_audit.py when AI provider is configured)

# Step 4: Apply policy gate
./scripts/agentos gate --stage pr --input injection-findings.json
```

### 3. Using Feedback for Continuous Improvement

When user says "This finding is wrong - test files should be ignored":

```bash
# Record feedback to improve future scans
./scripts/agentos feedback record finding-abc123 \
  --mark fp \
  --reason "Test fixture file in tests/ directory"

# View feedback statistics to track improvements
./scripts/agentos feedback stats
# Output: Shows FP rate by scanner, finding type, recent feedback

# AI triage automatically incorporates past feedback as few-shot examples
# on subsequent scans (when feedback system is integrated)
```

### 4. Analyzing AI Decision Quality

When investigating "Why are so many findings suppressed?":

```bash
# Analyze AI triage decisions
python scripts/decision_analyzer.py --log-file .agent-os-cache/decisions.jsonl

# Output includes:
# - Suppression/escalation rates
# - Confidence distributions
# - Patterns (e.g., "always suppresses test files")
# - Improvement suggestions

# Filter by scanner
python scripts/decision_analyzer.py --scanner semgrep --days 7

# Export analysis as JSON for further processing
python scripts/decision_analyzer.py --format json > analysis.json
```

### 5. Explaining Specific Decisions

When asked "Why was finding xyz-789 suppressed?":

```bash
# Decision logs contain reasoning for every AI triage decision
cat .agent-os-cache/decisions.jsonl | grep "xyz-789"

# Output shows:
# - Finding ID and type
# - Decision (suppress/escalate)
# - AI's reasoning
# - Confidence score
# - Noise score from heuristics
# - Model used
```

### Key Principles for Agents

1. **Discover, don't assume:** Agent-OS capabilities evolve. Use discovery commands to find available scanners and rules
2. **Compose primitives:** Chain commands (scan → normalize → triage → gate) for custom workflows
3. **Use feedback loops:** Mark findings as TP/FP to improve future scans
4. **Provide context:** Use `--project-type` and custom prompts to give AI domain-specific info
5. **Verify decisions:** Use decision analyzer to understand why AI made specific choices
6. **Iterate:** Start with quick scans, refine based on feedback and analysis

### Emergent Capabilities

By composing primitives, agents can create workflows without hard-coding:

- **Incremental scanning:** Scan only changed files in PR using `--only-changed`
- **Targeted audits:** Focus on specific CWEs or OWASP categories with Semgrep rule filters
- **Custom policies:** Combine scanner outputs with Rego logic for domain-specific gates
- **Compliance reports:** Filter findings by compliance framework (PCI-DSS, SOC2) using custom Rego policies
- **Trend analysis:** Track decision quality over time with historical log analysis

### Available CLI Tools

| Command | Purpose | Example |
|---------|---------|---------|
| `run_ai_audit.py` | Full security audit with AI triage | `python scripts/run_ai_audit.py --project-type backend-api` |
| `agentos normalize` | Normalize scanner outputs to unified format | `agentos normalize --inputs semgrep.sarif --output findings.json` |
| `agentos gate` | Apply policy gates (PR/release) | `agentos gate --stage pr --input findings.json` |
| `agentos feedback record` | Record finding feedback (TP/FP) | `agentos feedback record abc-123 --mark fp --reason "test file"` |
| `agentos feedback stats` | View feedback statistics | `agentos feedback stats` |
| `decision_analyzer.py` | Analyze AI decision quality | `python scripts/decision_analyzer.py --days 7` |
| `feedback_collector.py` | Manage feedback data | `python scripts/feedback_collector.py stats` |

### Integration with External Systems

Agents can integrate Agent-OS into larger workflows:

```bash
# Example: GitHub Actions integration with feedback collection
# 1. Run security scan
python scripts/run_ai_audit.py --output-file findings.json

# 2. Parse findings and collect feedback from PR comments
# (Custom script parses PR comments like "Finding abc-123 is FP: test file")

# 3. Record feedback
cat pr-feedback.txt | while read finding_id feedback reason; do
  ./scripts/agentos feedback record $finding_id --mark $feedback --reason "$reason"
done

# 4. Re-run scan with improved AI using feedback
python scripts/run_ai_audit.py --output-file improved-findings.json
```

### Performance Optimization

For large repos, agents should:

1. **Use caching:** Intelligent caching speeds up repeat scans 10-100x
   ```bash
   # Cache is automatic in .agent-os-cache/
   # View cache stats
   python scripts/cache_manager.py stats
   ```

2. **Scan incrementally:** Focus on changed files
   ```bash
   CHANGED_FILES=$(git diff --name-only origin/main...)
   python scripts/run_ai_audit.py --only-changed $CHANGED_FILES
   ```

3. **Use cost limits:** Prevent budget overruns
   ```bash
   python scripts/run_ai_audit.py --cost-limit 1.0  # Max $1.00 USD
   ```

4. **Filter by file type:** Skip non-code files
   ```bash
   python scripts/run_ai_audit.py --file-extensions .py,.js,.go
   ```

### Debugging and Troubleshooting

When things go wrong:

```bash
# Enable debug logging
python scripts/run_ai_audit.py --debug

# Check decision logs for low-confidence decisions
python scripts/decision_analyzer.py --format json | \
  jq '.analysis.low_confidence_decisions[]'

# Validate scanner configurations
semgrep --validate
trivy --version
trufflehog --version

# Clear caches if results seem stale
python scripts/cache_manager.py clear
```

## Important Notes

### Architecture Highlights
- **Multi-stage scanning:** Scanners run in parallel, results normalized, then AI triage applied
- **Noise reduction pipeline:** Heuristic filters → ML noise scoring → AI triage → deduplication
- **Cost optimization:** Intelligent caching reduces redundant scanner and AI calls
- **Policy as code:** Rego policies define when to block PRs/releases
- **Orchestrator pattern:** Modular design with scanner and workflow orchestrators for maintainability

### Performance Considerations
- P95 runtime: <5 minutes for typical repos
- Parallel scanner execution for efficiency
- File filtering to stay within token limits
- Intelligent caching reduces repeat scans and AI calls
- Rich progress bars provide real-time feedback on long-running operations

### Security Considerations
- All scanning runs in GitHub Actions runner (no external data)
- API keys stored as secrets
- Sandboxed exploit validation in Docker
- No telemetry or data collection

### Known Limitations
- Claude/GPT-4 costs ~$0.35 per run (caching can reduce this significantly)
- Large repos may hit token limits
- Some scanners require specific file types
- Ollama requires local setup and model download

### Development Tips
- Use Ollama for cost-free local development
- Enable debug logging with `--debug` flag
- Test with small repos first
- Review SARIF output for GitHub integration
- Caching significantly speeds up repeated runs

### Integration Points
- **GitHub:** PR comments, SARIF upload, workflow triggers
- **Anthropic/OpenAI/Ollama:** AI providers for intelligent triage
- **Docker:** Sandbox validation environment
- **Rich:** Terminal UI with progress bars and formatted output

This action represents a sophisticated security automation platform combining traditional scanning tools with modern AI capabilities to provide comprehensive, intelligent security coverage while minimizing false positives.