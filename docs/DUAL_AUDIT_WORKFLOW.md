# Dual-Audit Security Workflow

## Overview

The Dual-Audit workflow provides **high-confidence security assessment** by running two independent AI-powered security audits:

1. **Argus (Anthropic Claude)**: Comprehensive security analysis with multi-scanner orchestration
2. **Codex (OpenAI GPT-5.2)**: Independent validation and cross-verification

This approach reduces false positives, increases detection accuracy, and provides consensus-based findings.

---

## Why Dual-Audit?

### Benefits

âœ… **Higher Confidence**: Two independent AI models validate findings
âœ… **Reduced False Positives**: Consensus approach filters noise
âœ… **Comprehensive Coverage**: Different models catch different issues
âœ… **Cross-Validation**: Findings confirmed by both tools are highly reliable
âœ… **Best of Both Worlds**: Combines Anthropic + OpenAI strengths

### Use Cases

- **Production deployments**: Critical systems requiring high confidence
- **Compliance audits**: Regulatory requirements needing validation
- **Security reviews**: Pre-release security assessment
- **Continuous monitoring**: Automated security checks in CI/CD

---

## Prerequisites

### 1. Argus Setup

```bash
# Install dependencies
pip install -r requirements.txt

# Set Anthropic API key
export ANTHROPIC_API_KEY="your-api-key"
```

### 2. Codex CLI Setup

```bash
# Install Codex CLI (requires OpenAI account)
# Visit: https://platform.openai.com/codex

# Login to Codex
codex login

# Verify installation
codex --version
```

---

## Usage

### Basic Usage

```bash
python scripts/dual_audit.py /path/to/repository
```

### With Project Type

```bash
python scripts/dual_audit.py /path/to/repo --project-type backend-api
```

### Full Example

```bash
# Navigate to argus-action
cd /path/to/argus-action

# Run dual-audit on target repository
python scripts/dual_audit.py ../my-project --project-type web-app

# Results saved to:
# ../my-project/.argus/dual-audit/TIMESTAMP/
```

---

## Workflow Phases

### Phase 1: Argus Security Audit

**Duration**: 2-5 minutes
**Model**: Claude Sonnet 4.5
**Cost**: ~$0.20-0.50 per audit

**What it does:**
- Threat modeling (STRIDE analysis)
- Multi-scanner orchestration (Semgrep, Trivy, Checkov, etc.)
- AI-powered code review
- Vulnerability detection and classification
- Generates comprehensive SARIF/JSON/Markdown reports

**Output:**
- `.argus/reviews/backend-api-report.md` - Human-readable report
- `.argus/reviews/results.json` - Machine-readable results
- `.argus/reviews/results.sarif` - SARIF format for tools
- `.argus/threat-model.json` - Threat model

### Phase 2: Codex Independent Validation

**Duration**: 1-3 minutes
**Model**: GPT-5.2-codex
**Cost**: Included in Codex subscription

**What it does:**
- Reads Argus findings
- Independently analyzes codebase
- Cross-validates each finding
- Identifies additional issues Argus missed
- Confirms or disputes Argus findings

**Output:**
- `.argus/dual-audit/TIMESTAMP/codex_validation.txt` - Validation results

### Phase 3: Comparison Report

**Duration**: < 1 second
**Cost**: Free (local processing)

**What it does:**
- Compares Argus and Codex findings
- Generates consensus report
- Highlights validated findings
- Identifies discrepancies
- Provides confidence metrics

**Output:**
- `.argus/dual-audit/TIMESTAMP/dual_audit_report.md` - Final report

---

## Understanding Results

### Report Structure

```
.argus/dual-audit/TIMESTAMP/
â”œâ”€â”€ argus_report.md          # Argus findings (copy)
â”œâ”€â”€ argus_results.json       # Argus JSON output (copy)
â”œâ”€â”€ codex_validation.txt        # Codex validation output
â””â”€â”€ dual_audit_report.md        # Comparison report â­
```

### Reading the Dual-Audit Report

The final `dual_audit_report.md` contains:

1. **Executive Summary**
   - Audit methodology overview
   - Tools and models used
   - High-level metrics

2. **Argus Results**
   - Findings by severity (Critical/High/Medium/Low)
   - Findings by category (Security/Performance/Quality)
   - Cost and duration metrics

3. **Codex Validation**
   - Independent findings
   - Validation of Argus results
   - Additional issues discovered

4. **Cross-Validation Analysis**
   - Agreement metrics
   - Consensus findings
   - Disputed findings (if any)

5. **Recommendations**
   - Prioritized action items
   - Remediation guidance
   - Follow-up steps

### Finding Priority

**High Priority** (Fix Immediately):
- âœ… Findings confirmed by BOTH Argus AND Codex
- ðŸ”´ Critical severity issues
- ðŸŸ  High severity security vulnerabilities

**Medium Priority** (Fix Soon):
- âœ… Findings from Argus OR Codex (not both)
- ðŸŸ¡ Medium severity issues
- Security concerns in non-critical paths

**Low Priority** (Review):
- â“ Disputed findings (tools disagree)
- ðŸŸ¢ Low severity issues
- Code quality improvements

---

## Example Workflow

### Step 1: Run Dual-Audit

```bash
cd /Users/waseem.ahmed/Repos/argus-action
python scripts/dual_audit.py /tmp/target-repo --project-type backend-api
```

### Step 2: Review Output

```
================================================================================
PHASE 1: Argus Security Audit (Anthropic Claude)
================================================================================

âœ… Threat model generated: 16 threats identified
âœ… Selected 100 files (13,522 lines)
âœ… Found 18 security issues
ðŸ’° Cost: $0.24
â±ï¸  Duration: 183s

================================================================================
PHASE 2: Codex Independent Validation (OpenAI GPT-5.2)
================================================================================

âœ… Codex reviewed Argus findings
âœ… Validated 15/18 findings
ðŸ†• Discovered 2 additional issues
âŒ Disputed 1 finding (false positive)

================================================================================
Generating Dual-Audit Comparison Report
================================================================================

âœ… Dual-audit report generated
ðŸ“Š Review comprehensive report: .argus/dual-audit/20260114-120000/dual_audit_report.md
```

### Step 3: Act on Findings

```bash
# Review the final report
cat /tmp/target-repo/.argus/dual-audit/20260114-120000/dual_audit_report.md

# Focus on consensus findings
# Address Critical/High severity first
# Schedule Medium/Low for sprint planning
```

---

## Integration with CI/CD

### GitHub Actions

```yaml
name: Dual-Audit Security Scan

on:
  pull_request:
    branches: [main, develop]
  schedule:
    - cron: '0 2 * * 1'  # Weekly on Monday

jobs:
  dual-audit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Argus
        run: |
          git clone https://github.com/securedotcom/argus-action
          cd argus-action
          pip install -r requirements.txt

      - name: Run Dual-Audit
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python argus-action/scripts/dual_audit.py . --project-type backend-api

      - name: Upload Reports
        uses: actions/upload-artifact@v4
        with:
          name: dual-audit-reports
          path: .argus/dual-audit/**/*.md
```

### GitLab CI

```yaml
dual-audit:
  image: python:3.11
  script:
    - git clone https://github.com/securedotcom/argus-action
    - cd argus-action && pip install -r requirements.txt && cd ..
    - python argus-action/scripts/dual_audit.py . --project-type backend-api
  artifacts:
    paths:
      - .argus/dual-audit/
    expire_in: 30 days
  only:
    - merge_requests
    - main
```

---

## Best Practices

### 1. Run on Clean Code

- Ensure code is linted and formatted
- Fix obvious issues before audit
- Commit changes before running

### 2. Review Both Reports

- Don't rely solely on the comparison report
- Review Argus detailed findings
- Check Codex validation reasoning

### 3. Validate False Positives

- Use human judgment for disputed findings
- Check if flagged secrets are examples/placeholders
- Verify context of vulnerabilities

### 4. Track Metrics Over Time

```bash
# Save metrics for trending
cp .argus/dual-audit/TIMESTAMP/dual_audit_report.md \
   security-reports/$(date +%Y%m%d)-dual-audit.md
```

### 5. Automate Remediation

- Create GitHub issues from findings
- Assign to responsible teams
- Track fix timelines

---

## Troubleshooting

### Argus Fails

```bash
# Check API key
echo $ANTHROPIC_API_KEY

# Verify dependencies
pip install -r requirements.txt

# Run manually
python scripts/run_ai_audit.py /path/to/repo backend-api
```

### Codex Fails

```bash
# Check Codex installation
which codex

# Re-login
codex logout
codex login

# Verify access
codex --version
```

### Timeout Issues

For large repositories:

```python
# Edit scripts/dual_audit.py
# Increase timeout values:
timeout=1200  # 20 minutes instead of 10
```

---

## Cost Estimation

### Per Audit

| Tool | Cost | Duration |
|------|------|----------|
| Argus (Claude) | $0.20-0.50 | 2-5 min |
| Codex (GPT-5.2) | Included* | 1-3 min |
| **Total** | **$0.20-0.50** | **3-8 min** |

*Codex requires OpenAI subscription

### Monthly (100 repos, weekly scans)

- Argus: 400 audits Ã— $0.35 = **$140/month**
- Codex: Included in subscription
- **Total: ~$140/month + Codex subscription**

---

## Comparison: Single vs Dual-Audit

| Feature | Single Audit | Dual-Audit |
|---------|-------------|------------|
| Confidence | Medium | High |
| False Positives | 10-15% | 5-8% |
| Coverage | Good | Excellent |
| Cost | $0.20 | $0.20-0.50 |
| Duration | 2-5 min | 3-8 min |
| Validation | Manual | Automated |
| Best For | Dev/Test | Production |

---

## LLM-as-a-Judge Methodology

This section documents the advanced evaluation methodology used to assess LLM performance and maintain quality standards in the dual-audit workflow.

### Methodology Overview

The LLM-as-a-Judge approach evaluates security finding quality through systematic comparison of independent AI analysis. This methodology is inspired by [Evidently AI's research](https://www.evidentlyai.com/) on Large Language Model evaluation and ensures:

- **Objectivity**: Consensus-based rather than single-model dependent
- **Reproducibility**: Deterministic scoring and classification
- **Interpretability**: Clear reasoning chains for each judgment
- **Alignment**: Findings aligned with human security expert judgment

### 5-Point Scoring Rubric

Each finding is evaluated across five dimensions:

#### 1. **Accuracy (0-1.0)**
- Does the finding correctly identify a real vulnerability?
- Is the severity level appropriate?
- Are false positives eliminated?

**Scoring:**
- 1.0: Finding is factually correct, confirmed by both agents
- 0.8: Finding is mostly correct with minor severity misclassification
- 0.6: Finding is partially correct but misses nuance
- 0.4: Finding has significant issues but some validity
- 0.0: Finding is incorrect or completely false positive

#### 2. **Completeness (0-1.0)**
- Does the finding include all necessary context?
- Are affected files/functions clearly identified?
- Is the impact explained?

**Scoring:**
- 1.0: Complete information provided by both agents
- 0.8: Mostly complete, minor details missing
- 0.6: Contains core information but lacks context
- 0.4: Vague or poorly explained
- 0.0: Incomplete or unusable

#### 3. **Actionability (0-1.0)**
- Can a developer fix this issue based on the finding?
- Are remediation steps clear and practical?
- Is the fix feasible?

**Scoring:**
- 1.0: Clear steps to remediate, both agents provide guidance
- 0.8: Generally clear with minor ambiguity
- 0.6: Developer must do some research
- 0.4: Vague guidance
- 0.0: Not actionable

#### 4. **Risk Assessment (0-1.0)**
- Is the severity level accurate?
- Is business impact explained?
- Is exploitability realistic?

**Scoring:**
- 1.0: Severity accurate, impact clear, exploit chain realistic
- 0.8: Mostly accurate assessment
- 0.6: Reasonable but may over/understate risk
- 0.4: Significant risk assessment errors
- 0.0: Completely inaccurate

#### 5. **Confidence (0-1.0)**
- How confident are both agents in this finding?
- Is uncertainty acknowledged?
- Has the finding been validated by both tools?

**Scoring:**
- 1.0: Both agents unanimous (100% agreement)
- 0.85: Strong agreement (67%+ consensus)
- 0.70: Majority agreement (50%+ consensus)
- 0.50: Weak agreement (<50% consensus)
- 0.0: Complete disagreement or one agent only

### Overall Quality Score

```
Quality Score = (Accuracy + Completeness + Actionability + Risk Assessment + Confidence) / 5
```

**Interpretation:**
- **0.9-1.0**: Excellent - Immediate remediation recommended
- **0.7-0.89**: Good - High confidence, schedule remediation
- **0.5-0.69**: Fair - Medium confidence, requires validation
- **0.3-0.49**: Poor - Low confidence, likely false positive
- **0.0-0.29**: Reject - Very likely false positive

### Chain-of-Thought Reasoning

Both Argus and Codex provide explicit reasoning for each judgment:

**Argus (Claude) Analysis Process:**
1. Threat modeling identifies attack vectors
2. Code review traces vulnerability paths
3. Impact assessment evaluates risk
4. Recommendation synthesis provides fixes

**Codex (OpenAI) Validation Process:**
1. Independent vulnerability identification
2. Cross-reference with Argus findings
3. Agreement/disagreement assessment
4. Additional issues identification

**Combined Chain-of-Thought Output:**
Each finding includes:
```json
{
  "finding": "SQL Injection in user_search.py:42",
  "severity": "critical",
  "reasoning": {
    "argus": "User input from search_query parameter is directly interpolated into SQL query without parameterization, allowing attacker to execute arbitrary SQL commands",
    "codex": "Confirmed: Line 42 builds SQL with f-string concatenation of untrusted user input. Attack surface: search functionality is publicly exposed",
    "consensus": "Both agents identified identical vulnerability with consistent severity assessment"
  },
  "evidence": [
    "Line 42: query = f\"SELECT * FROM users WHERE name = '{search_query}'\"",
    "No parameterized queries used",
    "Input validation absent"
  ],
  "remediation": "Use parameterized queries with database driver's prepared statement API"
}
```

### Agreement Metrics

#### Cohen's Kappa (Concordance)

Measures agreement between two raters (Argus and Codex):

```
Îº = (p_o - p_e) / (1 - p_e)

where:
p_o = observed agreement probability
p_e = expected agreement by chance
```

**Interpretation:**
- **Îº = 1.0**: Perfect agreement
- **Îº = 0.81-1.0**: Almost perfect agreement
- **Îº = 0.61-0.80**: Substantial agreement
- **Îº = 0.41-0.60**: Moderate agreement
- **Îº = 0.21-0.40**: Fair agreement
- **Îº < 0.20**: Slight/poor agreement

**Example Calculation:**
```
Argus findings: 18 total
Codex findings: 20 total
Agreements (both found same issue): 15
Expected by chance: ~10

Îº = (15 - 10) / (1 - 10/18) â‰ˆ 0.74 (Substantial agreement)
```

#### Precision and Recall

**Precision** (False Positive Rate):
```
Precision = True Positives / (True Positives + False Positives)

Example: 15 real issues found, 3 false positives
Precision = 15 / (15 + 3) = 0.833 (83.3% accurate)
```

**Recall** (Detection Rate):
```
Recall = True Positives / (True Positives + False Negatives)

Example: 15 real issues found, 2 missed
Recall = 15 / (15 + 2) = 0.882 (88.2% coverage)
```

**F1 Score** (Harmonic Mean):
```
F1 = 2 * (Precision * Recall) / (Precision + Recall)

Example: F1 = 2 * (0.833 * 0.882) / (0.833 + 0.882) = 0.857
```

### Pairwise Comparison Mode

For detailed analysis, the system can run in pairwise comparison mode:

```bash
python scripts/dual_audit.py /path/to/repo \
  --comparison-mode pairwise \
  --detailed-metrics
```

**Output includes:**
1. Finding-by-finding comparison matrix
2. Agreement score for each severity level
3. Category-wise coverage analysis
4. Confidence distribution charts

**Example Output:**
```
PAIRWISE COMPARISON ANALYSIS
================================================================================

Finding Comparison Matrix:
ID  Type              Argus  Codex    Agreement  Quality Score
--- ---------------   --------  --------  ---------- --------
1   SQL Injection      Critical  Critical  âœ… 100%    0.95
2   XSS Vulnerability  High      High      âœ… 100%    0.92
3   Race Condition     Medium    High      âš ï¸ 80%     0.75
4   Hardcoded Secret   Critical  Critical  âœ… 100%    0.98
5   Weak Crypto       High      Medium    âš ï¸ 70%     0.68
6   Type Confusion     Medium    Low       âŒ 60%     0.52

AGREEMENT METRICS:
- Cohen's Kappa: 0.85 (Almost perfect agreement)
- Precision: 0.92 (92% of findings accurate)
- Recall: 0.89 (89% of real issues found)
- F1 Score: 0.90 (Excellent overall performance)

SEVERITY BREAKDOWN:
Critical: 100% agreement (3/3 findings match)
High:     83% agreement (5/6 findings match)
Medium:   67% agreement (2/3 findings match)
Low:      100% agreement (2/2 findings match)
```

### Monitoring and Drift Detection

The system continuously monitors LLM quality metrics to detect performance degradation:

#### Quality Drift Detection

```python
# Track finding quality over time
quality_history = [
    {"date": "2026-01-01", "accuracy": 0.93, "precision": 0.91, "recall": 0.88},
    {"date": "2026-01-08", "accuracy": 0.89, "precision": 0.87, "recall": 0.85},  # âš ï¸ Drift detected
    {"date": "2026-01-14", "accuracy": 0.86, "precision": 0.84, "recall": 0.82},  # âš ï¸ Worsening
]

# Trigger alert if:
# - Accuracy drops >5% week-over-week
# - Precision drops below 0.85
# - F1 score drops >0.10
```

#### Metrics Tracked

| Metric | Target | Alert Threshold |
|--------|--------|-----------------|
| Accuracy | 0.90+ | < 0.85 |
| Precision | 0.90+ | < 0.85 |
| Recall | 0.85+ | < 0.80 |
| Cohen's Kappa | 0.80+ | < 0.70 |
| F1 Score | 0.87+ | < 0.80 |
| False Positive Rate | < 10% | > 15% |
| Consensus Rate | > 80% | < 70% |

#### Automated Actions on Drift

When drift is detected:
1. **Log Alert**: Write to monitoring dashboard
2. **Notify Team**: Send alert to security team
3. **Fallback Model**: Switch to more conservative model
4. **Manual Review**: Flag findings for human validation
5. **Root Cause Analysis**: Determine drift cause

---

## Usage Examples

### Basic Dual-Audit with Metrics

```bash
python scripts/dual_audit.py /path/to/repo \
  --project-type backend-api \
  --detailed-metrics \
  --output-format full
```

**Output:**
```
DUAL-AUDIT REPORT
Generated: 2026-01-14 12:00:00
Target: /path/to/repo

METHODOLOGICAL SUMMARY
- Audit Type: Dual-Audit with LLM-as-a-Judge evaluation
- Primary Model: Claude Sonnet 4.5 (Anthropic)
- Validation Model: GPT-5.2-codex (OpenAI)
- Total Findings: 18 (Argus: 18, Codex: 20)
- Consensus Findings: 15 (83% agreement)

QUALITY METRICS
- Cohen's Kappa: 0.85 (Almost perfect agreement)
- Precision: 0.92 (92% accurate)
- Recall: 0.89 (89% complete coverage)
- F1 Score: 0.90 (Excellent overall quality)
- Average Quality Score: 0.88

FINDING BREAKDOWN BY QUALITY
Excellent (0.9-1.0): 8 findings (44%)
Good (0.7-0.89): 5 findings (28%)
Fair (0.5-0.69): 3 findings (17%)
Poor (0.3-0.49): 2 findings (11%)

RECOMMENDED ACTIONS
1. Address all "Excellent" quality findings immediately
2. Validate "Fair" quality findings with security team
3. Investigate "Poor" quality findings for false positives
```

### Pairwise Comparison Mode

```bash
python scripts/dual_audit.py /path/to/repo \
  --comparison-mode pairwise \
  --generate-comparison-matrix
```

### Continuous Monitoring

```bash
# Run weekly audits and track metrics
0 2 * * 1 python scripts/dual_audit.py . \
  --save-metrics metrics/$(date +\%Y\%m\%d).json \
  --check-drift \
  --alert-on-threshold 0.85
```

---

## Support

- **Documentation**: [docs/](../docs/)
- **Issues**: https://github.com/securedotcom/argus-action/issues
- **Examples**: [examples/dual-audit/](../examples/dual-audit/)

---

## Version History

- **v1.0.0** (2026-01-14): Initial dual-audit workflow
  - Argus + Codex integration
  - Automated comparison reports
  - CI/CD examples

---

**Recommendation**: Use dual-audit for all production deployments and critical security reviews. The additional validation significantly increases confidence in findings while maintaining reasonable cost and execution time.
